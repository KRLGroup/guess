{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Embedding, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, LSTM, TimeDistributed, MaxPooling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElapsedTimer:\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "    def __elapsed(self,sec):\n",
    "        if sec < 60:\n",
    "            return str(sec) + \" sec\"\n",
    "        elif sec < (60 * 60):\n",
    "            return str(sec / 60) + \" min\"\n",
    "        else:\n",
    "            return str(sec / (60 * 60)) + \" hr\"\n",
    "    def elapsed_time(self):\n",
    "        return self.__elapsed(time.time() - self.start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaserScans:\n",
    "    def __init__(self, verbose=False):\n",
    "        self.verbose = verbose\n",
    "        self.timesteps = None\n",
    "        self.cmd_vel = None\n",
    "        self.scans = None\n",
    "        self.scan_bound_percentage = 0\n",
    "\n",
    "    def load(self, datafile, clip_scans_at=None, scan_center_range=None, scan_bound_percentage=None):\n",
    "        self.clip_scans_at = clip_scans_at\n",
    "        self.scan_center_range = scan_center_range\n",
    "        self.scan_bound_percentage = scan_bound_percentage\n",
    "        self.data = np.loadtxt(datafile).astype('float32')\n",
    "\n",
    "        self.timesteps = self.data[:, :1]\n",
    "        self.cmd_vel = self.data[:, 1:7]\n",
    "        self.scans = self.data[:, 7:]\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"timesteps --\", self.timesteps.shape)\n",
    "            print(\"cmd_vel --\", self.cmd_vel.shape)\n",
    "            print(\"scans --\", self.scans.shape, \"range [\", np.max(self.scans), \"-\", np.min(self.scans), \"]\")\n",
    "\n",
    "        if not self.clip_scans_at is None:\n",
    "            np.clip(self.scans, a_min=0, a_max=self.clip_scans_at, out=self.scans)\n",
    "\n",
    "        if not self.scan_center_range is None:\n",
    "            i_range = 0.5*self.scans.shape[1] - 0.5*self.scan_center_range\n",
    "            i_range = i_range + 20\n",
    "            self.scan_bound_percentage = 1.0 - (float(self.scan_center_range)/self.scans.shape[1])\n",
    "            self.scan_bound_percentage = 0.5*self.scan_bound_percentage\n",
    "            self.scans = self.scans[:, int(i_range):int(i_range) + self.scan_center_range]\n",
    "        else:\n",
    "            if self.scan_bound_percentage != 0:\n",
    "                min_bound = int(self.scan_bound_percentage*self.scans.shape[1])\n",
    "                max_bound = int(self.scans.shape[1] - self.scan_bound_percentage*self.scans.shape[1])\n",
    "                self.scans = self.scans[:, min_bound:max_bound]\n",
    "                if self.verbose: print(\"scans bounds (min, max)=\", min_bound, max_bound)\n",
    "        self.scans = self.scans / self.clip_scans_at    # normalization makes the vae work\n",
    "\n",
    "    def initRand(self, rand_scans_num, scan_dim, clip_scans_at=1.0):\n",
    "        self.scans = np.random.uniform(0.0, clip_scans_at, size=[rand_scans_num, scan_dim])\n",
    "        self.cmd_vel = np.zeros((rand_scans_num, 6))\n",
    "        self.timesteps = np.zeros((rand_scans_num, 1))\n",
    "\n",
    "    def originalScansDim(self):\n",
    "        if self.scans is None: return -1\n",
    "        return self.scans.shape[1]\n",
    "\n",
    "    def timesteps(self):\n",
    "        if self.timesteps is None: return np.zeros((1, 1))\n",
    "        return self.timesteps\n",
    "\n",
    "    def cmdVel(self):\n",
    "        if self.cmd_vel is None: return np.zeros((1, 1))\n",
    "        return self.cmd_vel\n",
    "\n",
    "    def getScans(self, split_at=0):\n",
    "        if self.scans is None: return np.zeros((1, 1))\n",
    "        if split_at == 0: return self.scans\n",
    "\n",
    "        x_train = self.scans[:int(self.scans.shape[0]*split_at), :]\n",
    "        x_test = self.scans[int(self.scans.shape[0]*split_at):, :]\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"scans train:\", x_train.shape)\n",
    "            print(\"scans test:\", x_test.shape)\n",
    "\n",
    "        return x_train, x_test\n",
    "\n",
    "    def getScanSegments(self, scan, threshold):\n",
    "        segments = []\n",
    "        iseg = 0\n",
    "        useg = bool(scan[0] > threshold)\n",
    "        for d in range(scan.shape[0]):\n",
    "            if useg and scan[d] < threshold:\n",
    "                segments.append([iseg, d, useg])\n",
    "                iseg = d\n",
    "                useg = False\n",
    "            if not useg and scan[d] > threshold:\n",
    "                segments.append([iseg, d, useg])\n",
    "                iseg = d\n",
    "                useg = True\n",
    "            if d == scan.shape[0] - 1: segments.append([iseg, d, useg])\n",
    "        return segments\n",
    "\n",
    "    def plotScan(self, scan, y=None):\n",
    "        max_range = 75\n",
    "        i_range = -int(0.5*max_range)\n",
    "        theta = (3/2)*np.pi*0.01*np.arange(i_range, i_range + max_range, max_range/self.scan_center_range)\n",
    "        theta = theta[::-1]\n",
    "\n",
    "        x_axis = np.arange(scan.shape[0])\n",
    "        segments = self.getScanSegments(scan, 0.99)\n",
    "        if self.verbose: print(\"Segments -- \", np.array(segments).shape, \"--\", segments)\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(121)\n",
    "        y_axis = scan\n",
    "        if not y is None:\n",
    "            y_axis = y\n",
    "            plt.plot(x_axis, y_axis, color='lightgray')\n",
    "\n",
    "        plt.plot(x_axis, scan, color='lightgray')\n",
    "        for s in segments:\n",
    "            if s[2]:\n",
    "                col = '#ff7f0e'\n",
    "                plt.plot(x_axis[s[0]:s[1]], y_axis[s[0]:s[1]], 'o', markersize=0.5, color=col)\n",
    "            else:\n",
    "                col = '#1f77b4'\n",
    "                plt.plot(x_axis[s[0]:s[1]], scan[s[0]:s[1]], 'o', markersize=0.5, color=col)\n",
    "\n",
    "        plt.subplot(122, projection='polar')\n",
    "        plt.plot(theta, scan, color='lightgray')\n",
    "        for s in segments:\n",
    "            if s[2]:\n",
    "                col = '#ff7f0e'\n",
    "                plt.plot(theta[s[0]:s[1]], y_axis[s[0]:s[1]], 'o', markersize=0.5, color=col)\n",
    "            else:\n",
    "                col = '#1f77b4'\n",
    "                plt.plot(theta[s[0]:s[1]], scan[s[0]:s[1]], 'o', markersize=0.5, color=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE:\n",
    "    def __init__(self, original_dim, batch_size=128, latent_dim=10, intermediate_dim=128, verbose=False):\n",
    "        self.original_dim = original_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.intermediate_dim = intermediate_dim\n",
    "        self.verbose = verbose\n",
    "        self.reshape_rows = 32\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.vae = None\n",
    "        self.conv_model = False\n",
    "\n",
    "    def sampling(self, args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        # by default, random_normal has mean=0 and std=1.0\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    def __buildEncoder(self):\n",
    "        if not self.encoder is None: return self.encoder\n",
    "        input_shape = (self.original_dim,)\n",
    "        depth = 32\n",
    "        dropout = 0.4\n",
    "        \n",
    "        self.e_in = Input(shape=input_shape, name='encoder_input')\n",
    "        if self.conv_model:\n",
    "            enc = Reshape((self.reshape_rows, int(self.original_dim/self.reshape_rows), 1,))(self.e_in)\n",
    "            enc = Conv2D(depth, 5, strides=2, padding='same')(enc)\n",
    "            enc = Activation('relu')(enc)\n",
    "            enc = Dropout(dropout)(enc)\n",
    "            enc = Conv2D(depth*4, 5, strides=2, padding='same')(enc)\n",
    "            enc = LeakyReLU(alpha=0.2)(enc)\n",
    "            enc = Dropout(dropout)(enc)\n",
    "            # shape info needed to build decoder model\n",
    "            self.enc_shape = K.int_shape(enc)\n",
    "            # Out: 1-dim probability\n",
    "            enc = Flatten()(enc)\n",
    "        else: enc = self.e_in\n",
    "        enc = Dense(self.intermediate_dim, activation='relu')(enc)\n",
    "        \n",
    "        self.z_mean = Dense(self.latent_dim, name='z_mean')(enc)\n",
    "        self.z_log_var = Dense(self.latent_dim, name='z_log_var')(enc)\n",
    "        z = Lambda(self.sampling, output_shape=(self.latent_dim,), name='z')([self.z_mean, self.z_log_var])\n",
    "        \n",
    "        self.encoder = Model(self.e_in, [self.z_mean, self.z_log_var, z], name='encoder')\n",
    "        if self.verbose: self.encoder.summary()\n",
    "        return self.encoder\n",
    "    \n",
    "    def __buildDecoder(self):\n",
    "        if not self.decoder is None: return self.decoder\n",
    "        depth = 2\n",
    "        dropout = 0.4\n",
    "        \n",
    "        d_in = Input(shape=(self.latent_dim,), name='z_sampling')\n",
    "        if self.conv_model:\n",
    "            dec = Dense(self.enc_shape[1]*self.enc_shape[2]*self.enc_shape[3], activation='relu')(d_in)\n",
    "            dec = Reshape((self.enc_shape[1], self.enc_shape[2], self.enc_shape[3]))(dec)\n",
    "\n",
    "            dec = Conv2DTranspose(filters=depth*8, kernel_size=5,\n",
    "                              activation='relu', strides=2, padding='same')(dec)\n",
    "            dec = Conv2DTranspose(filters=depth*4, kernel_size=5,\n",
    "                              activation='relu', strides=2, padding='same')(dec)\n",
    "            dec = Dropout(dropout)(dec)\n",
    "            dec = Dense(depth, activation='sigmoid')(dec)\n",
    "            dec = Flatten()(dec)\n",
    "        else:\n",
    "            dec = Dense(self.intermediate_dim, activation='sigmoid')(d_in)\n",
    "            \n",
    "        d_out = Dense(self.original_dim, activation='relu')(dec)\n",
    "\n",
    "        # instantiate decoder model\n",
    "        self.decoder = Model(d_in, d_out, name='decoder')\n",
    "        if self.verbose: self.decoder.summary()\n",
    "        return self.decoder\n",
    "        \n",
    "    def buildModel(self):\n",
    "        if not self.vae is None: return self.vae\n",
    "        self.__buildEncoder()\n",
    "        self.__buildDecoder()\n",
    "        \n",
    "        vae_out = self.decoder(self.encoder(self.e_in)[2])\n",
    "        self.vae = Model(self.e_in, vae_out, name='vae_mlp')\n",
    "        \n",
    "        reconstruction_loss = binary_crossentropy(self.e_in, vae_out)\n",
    "        reconstruction_loss *= self.original_dim\n",
    "        \n",
    "        kl_loss = 1 + self.z_log_var - K.square(self.z_mean) - K.exp(self.z_log_var)\n",
    "        kl_loss = K.sum(kl_loss, axis=-1)\n",
    "        kl_loss *= -0.5\n",
    "        vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "        self.vae.add_loss(vae_loss)\n",
    "        self.vae.compile(optimizer=Adam(lr=0.0001))\n",
    "        if self.verbose: self.VAE.summary()\n",
    "        return self.vae\n",
    "\n",
    "    def fitModel(self, x, x_test=None, epochs=10, verbose=None):\n",
    "        if x_test is None:\n",
    "            self.vae.fit(x, epochs=epochs, batch_size=self.batch_size, verbose=verbose)\n",
    "        else:\n",
    "            self.vae.fit(x, epochs=epochs, batch_size=self.batch_size, verbose=verbose,\n",
    "                         validation_data=(x_test, None))\n",
    "\n",
    "    def encode(self, x, batch_size=None):\n",
    "        if len(x.shape) == 1: x = np.array([x])\n",
    "        z_mean, z_var_log, z = self.encoder.predict(x, batch_size=batch_size)\n",
    "        return z_mean\n",
    "\n",
    "    def decode(self, z_mean):\n",
    "        return self.decoder.predict(z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE:\n",
    "    def __init__(self, original_dim, batch_size=128, latent_dim=10, verbose=False):\n",
    "        self.original_dim = original_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.verbose = verbose\n",
    "        self.reshape_rows = 32\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.ae = None\n",
    "        \n",
    "    def buildModel(self):\n",
    "        if not self.ae is None: return self.ae\n",
    "        input_shape = (self.original_dim,)\n",
    "        depth = 265\n",
    "        dropout = 0.4\n",
    "        \n",
    "        #### ENCODER\n",
    "        e_in = Input(shape=input_shape, name='encoder_input')\n",
    "        enc=e_in\n",
    "        # enc = Reshape((self.reshape_rows, int(self.original_dim/self.reshape_rows), 1,))(e_in)\n",
    "        # enc = Conv2D(depth, 5, strides=2, activation='relu', padding='same')(enc)\n",
    "        # enc = Conv2D(int(depth/2), 5, strides=2, activation='relu', padding='same')(enc)\n",
    "        # enc = Conv2D(int(depth/4), 5, strides=2, activation='relu', padding='same')(enc)\n",
    "        # enc = Dropout(dropout)(enc)\n",
    "        # self.enc_shape = K.int_shape(enc)  # shape info needed to build decoder model\n",
    "        # enc = Flatten()(enc)\n",
    "        enc = Dense(depth, activation='relu')(enc)\n",
    "        e_out = Dense(self.latent_dim, activation='relu')(enc)\n",
    "        \n",
    "        self.encoder = Model(e_in, e_out, name='encoder')\n",
    "        if self.verbose: self.encoder.summary()\n",
    "        \n",
    "        #### DECODER\n",
    "        d_in = Input(shape=(self.latent_dim,), name='decoder_input')\n",
    "        dec=d_in\n",
    "        # dec = Dense(self.enc_shape[1]*self.enc_shape[2]*self.enc_shape[3], activation='relu')(d_in)\n",
    "        # dec = Reshape((self.enc_shape[1], self.enc_shape[2], self.enc_shape[3]))(dec)\n",
    "        # dec = Conv2DTranspose(filters=depth, kernel_size=5, activation='relu', strides=2, padding='same')(dec)\n",
    "        # dec = Conv2DTranspose(filters=int(depth/2), kernel_size=5, activation='relu', strides=2, padding='same')(dec)\n",
    "        # dec = Dropout(dropout)(dec)\n",
    "        dec = Dense(int(depth/32), activation='sigmoid')(dec)\n",
    "        # dec = Flatten()(dec)\n",
    "        d_out = Dense(self.original_dim, activation='relu')(dec)\n",
    "\n",
    "        self.decoder = Model(d_in, d_out, name='decoder')\n",
    "        if self.verbose: self.decoder.summary()\n",
    "        \n",
    "        #### AUTOENCODER\n",
    "        vae_out = self.decoder(self.encoder(e_in))\n",
    "        self.ae = Model(e_in, vae_out, name='autoencoder')\n",
    "        self.ae.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "        if self.verbose: self.ae.summary()\n",
    "        return self.ae\n",
    "    \n",
    "    def fitModel(self, x, x_test=None, epochs=10, verbose=None):\n",
    "        if x_test is None:\n",
    "            for e in range(epochs):\n",
    "                for i in range(0, x.shape[0] - self.batch_size, self.batch_size):\n",
    "                    self.ae.train_on_batch(x[i:i + self.batch_size], x[i:i + self.batch_size]) \n",
    "        else:\n",
    "            self.ae.fit(x, epochs=epochs, batch_size=self.batch_size,\n",
    "                        verbose=verbose, validation_data=(x_test, None))\n",
    "            \n",
    "    def encode(self, x, batch_size=None):\n",
    "        if len(x.shape) == 1: x = np.array([x])\n",
    "        return self.encoder.predict(x, batch_size=batch_size)\n",
    "        \n",
    "    def decode(self, latent):\n",
    "        return self.decoder.predict(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesteps -- (13545, 1)\n",
      "cmd_vel -- (13545, 6)\n",
      "scans -- (13545, 721) range [ 30.0 - 0.0 ]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # DIAG_first_floor.txt\n",
    "    # diag_labrococo.txt\n",
    "    # diag_underground.txt\n",
    "    ls = LaserScans(verbose=True)\n",
    "    ls.load(\"../../dataset/diag_underground.txt\", clip_scans_at=8, scan_center_range=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ae = VAE(ls.originalScansDim(), batch_size=128, latent_dim=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    ae.buildModel()\n",
    "    \n",
    "    x, x_test = ls.getScans(0.9)\n",
    "    ae.fitModel(x, x_test=None, epochs=50, verbose=0)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    batch_sz = 8\n",
    "    gan_batch_sz = 8\n",
    "    scan_idx = 2000\n",
    "\n",
    "    to_show_idx = 10\n",
    "    \n",
    "    scan = x[scan_idx:(scan_idx + batch_sz*gan_batch_sz)]\n",
    "    latent = ae.encode(scan)\n",
    "    \n",
    "    # plt.plot(latent[to_show_idx])\n",
    "    dscan = ae.decode(latent)\n",
    "    \n",
    "    ls.plotScan(scan[to_show_idx], dscan[to_show_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
